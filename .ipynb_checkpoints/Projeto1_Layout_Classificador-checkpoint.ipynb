{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Rodrigo de Lima Azeredo\n",
    "\n",
    "Nome: Ykaro de Sousa Andrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando bibliotecas\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display\n",
    "pd.options.display.max_rows = 13\n",
    "import emoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\Rodrigo Lima\\Documents\\Cdados\\Projeto\\projet1cdados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo fun√ß√£o de limpeza dos caracteres dos tweets e espa√ßando os emajis e palavras corretamente.\n",
    "\n",
    "def cleanup(text):\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;\\n)(*$#@''\"\"]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    text_subbed = emoji.get_emoji_regexp().split(text_subbed) #emoji\n",
    "    return ' '.join(text_subbed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'puma.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Irrelevante 0 / Relevante 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o neymar inovou a puma https://t.co/qtcuvd1svj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a @puma t√° deitando nas chuteiras do neymar, m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fico assim no da puma affss https://t.co/1ygyh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g_estrella__ puma t√° a√≠ , mas tr√™s listra t√° ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@0ketlyn_s eu acho que um puma ^^</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  \\\n",
       "0     o neymar inovou a puma https://t.co/qtcuvd1svj   \n",
       "1  a @puma t√° deitando nas chuteiras do neymar, m...   \n",
       "2  fico assim no da puma affss https://t.co/1ygyh...   \n",
       "3  @g_estrella__ puma t√° a√≠ , mas tr√™s listra t√° ...   \n",
       "4                  @0ketlyn_s eu acho que um puma ^^   \n",
       "\n",
       "   Irrelevante 0 / Relevante 1  \n",
       "0                            1  \n",
       "1                            1  \n",
       "2                            0  \n",
       "3                            1  \n",
       "4                            0  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Irrelevante 0 / Relevante 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@0chavex0 @ornate_puma vdd to resfriado</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üìΩ neymar e puma üëÄ‚ù§!!\\ntemos novidades vindo a√≠...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@brgmsch mas a puma nem patrocina a aston</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üìΩ puma neymar jr creativity  a inovadora chute...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a puma t√° a evoluir muito, quem me dera que o ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  \\\n",
       "0            @0chavex0 @ornate_puma vdd to resfriado   \n",
       "1  üìΩ neymar e puma üëÄ‚ù§!!\\ntemos novidades vindo a√≠...   \n",
       "2          @brgmsch mas a puma nem patrocina a aston   \n",
       "3  üìΩ puma neymar jr creativity  a inovadora chute...   \n",
       "4  a puma t√° a evoluir muito, quem me dera que o ...   \n",
       "\n",
       "   Irrelevante 0 / Relevante 1  \n",
       "0                            0  \n",
       "1                            1  \n",
       "2                            0  \n",
       "3                            1  \n",
       "4                            1  "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "Para nosso projeto escolhemos a marca de roupas Puma. A partir disso definimos como premissa que os tweets relevantes seriam aqueles que exaltavam a marca em seus coment√°rios, em contra partida os tweets irrelevantes seriam todos os outros, ou seja os que n√£o tinham rela√ß√£o direta com a marca e/ou falavam mal da Puma.\n",
    "\n",
    "###\n",
    "Para nossa an√°lise, escolhemos a marca Puma, onde nessa an√°lise foi pego como tweets relevantes, todos aqueles que enaltecia a marca, tais twitts como: Falando o quanto a marca √© boa e o quanto a mesma est√° crescendo no mercado.\n",
    "E qualificou-se como irrelevante os  tweets que rebaixava a marca ou os que realmente n√£o tinha haver com a marca.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todos os tweets: Treinamentos\n",
    "dados = pd.read_excel('puma.xlsx')\n",
    "#dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando apenas a planilha de Treinamentos.\n",
    "t_treinamento = dados.loc[:, 'Treinamento']\n",
    "#t_treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando os tweets de treinamento usando a fun√ß√£o que definimos como cleanup.\n",
    "lista_limpa = []\n",
    "for index, argumento in enumerate (t_treinamento):\n",
    "    #print(f'posi√ß√£o {index} tweeter: {argumento}')\n",
    "    limpa = cleanup(argumento.lower())\n",
    "    lista_limpa.append(limpa)\n",
    "    \n",
    "#print(lista_limpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Criando um novo data frame com os tweets de treinamentos limpos\n",
    "dados['Limpo'] = lista_limpa\n",
    "#dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando apenas os tweets relevantes e os adicionando em uma nova vari√°vel\n",
    "relevante = dados.loc[dados['Irrelevante 0 / Relevante 1'] == 1, 'Limpo']\n",
    "#relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1¬∞ for: Separar os tweets relevantes em palavras relevantes dando um split em cada tweet.\n",
    "p_relevantes = [] \n",
    "for c,conteudo in enumerate (relevante):\n",
    "    p_relevantes.append(conteudo.split())\n",
    "    \n",
    "#print(p_relevantes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Definindo todas as palvras revelantes em um conjunto\n",
    "todas_palavras_relevantes=[]\n",
    "for index, conteudo in enumerate(p_relevantes):\n",
    "    cont=0\n",
    "    while cont < len(p_relevantes[index]):\n",
    "        novo= conteudo[cont]\n",
    "        todas_palavras_relevantes.append(novo)\n",
    "        cont+=1\n",
    "#print(todas_palavras_relevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O total de Palavras relevantes √© 1730\n"
     ]
    }
   ],
   "source": [
    "# Informando o total de palavras dos tweets relevantes\n",
    "print(f' O total de Palavras relevantes √© {len(todas_palavras_relevantes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo uma nova limpeza, retirando todos os https.\n",
    "for index, conteudo in enumerate(todas_palavras_relevantes):\n",
    "    #print(f'{index}: {conteudo}')\n",
    "    cont = 0\n",
    "    while cont < len(todas_palavras_relevantes[index]):\n",
    "        #print(conteudo[cont])\n",
    "        if conteudo[cont:5] == 'https':\n",
    "            #print(f' palvra: {lista[index]} na posi√ß√£o {index}')\n",
    "            lista_de_links.append(todas_palavras_relevantes[index])\n",
    "        cont+=1\n",
    "\n",
    "lista_nova_r = []\n",
    "cont2 = 0\n",
    "while cont2 < len(todas_palavras_relevantes):\n",
    "    if todas_palavras_relevantes[cont2] not in lista_de_links:\n",
    "        lista_nova_r.append(todas_palavras_relevantes[cont2])\n",
    "    cont2+=1\n",
    "\n",
    "# Atualiza√ß√£o da vari√°vel todas_palavras_relevantes sem os https:\n",
    "\n",
    "todas_palavras_relevantes= lista_nova_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O total de Palavras relevantes sem os \"htpps\" √© 1691\n"
     ]
    }
   ],
   "source": [
    "print(f' O total de Palavras relevantes sem os \"htpps\" √© {len(todas_palavras_relevantes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Guardando as palavras como um pd.Series\n",
    "serie_relevante = pd.Series(todas_palavras_relevantes)\n",
    "\n",
    "# Frequencia absoluta de palavras relevantes\n",
    "tabela_relevante = serie_relevante.value_counts()\n",
    "#tabela_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Fazendo o mesmo para as palavras irrelevantes\"></div>\n",
    "\n",
    "### Fazendo o mesmo para as palavras irrelevantes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando apenas os tweets irrelevantes e os adicionando em uma nova vari√°vel\n",
    "irrelevante = dados.loc[dados['Irrelevante 0 / Relevante 1'] == 0, 'Limpo']\n",
    "#irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1¬∞ for: Separar os tweets relevantes em palavras irrelevantes dando um split em cada tweet.\n",
    "p_irrelevantes = []\n",
    "for index, conteudo in enumerate (irrelevante):\n",
    "    p_irrelevantes.append(conteudo.split())\n",
    "    \n",
    "# print(p_irrelevantes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Definindo todas as palvras irrevelantes em um conjunto\n",
    "todas_palavras_irrelevantes=[]\n",
    "for index, conteudo in enumerate(p_irrelevantes):\n",
    "    cont=0\n",
    "    while cont < len(p_irrelevantes[index]):\n",
    "        novo= conteudo[cont]\n",
    "        todas_palavras_irrelevantes.append(novo)\n",
    "        cont+=1\n",
    "#print(todas_palavras_irrelevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O total de Palavras irrelevantes √© 3115\n"
     ]
    }
   ],
   "source": [
    "# Informando o total de palavras dos tweets relevantes\n",
    "print(f' O total de Palavras irrelevantes √© {len(todas_palavras_irrelevantes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lista_de_links= []\n",
    "for index, conteudo in enumerate(todas_palavras_irrelevantes):\n",
    "    #print(f'{index}: {conteudo}')\n",
    "    cont = 0\n",
    "    while cont < len(todas_palavras_irrelevantes[index]):\n",
    "        #print(conteudo[cont])\n",
    "        if conteudo[cont:5] == 'https':\n",
    "            #print(f' palvra: {lista[index]} na posi√ß√£o {index}')\n",
    "            lista_de_links.append(todas_palavras_irrelevantes[index])\n",
    "        cont+=1\n",
    "\n",
    "lista_nova_irr = []\n",
    "cont2 = 0\n",
    "while cont2 < len(todas_palavras_irrelevantes):\n",
    "    if todas_palavras_irrelevantes[cont2] not in lista_de_links:\n",
    "        lista_nova_irr.append(todas_palavras_irrelevantes[cont2])\n",
    "    cont2+=1\n",
    "\n",
    "# Atualiza√ß√£o da vari√°vel todas_palavras_relevantes sem os https:\n",
    "\n",
    "todas_palavras_irrelevantes= lista_nova_irr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O total de Palavras irrelevantes sem os \"htpps\": 3067\n"
     ]
    }
   ],
   "source": [
    "print(f' O total de Palavras irrelevantes sem os \"htpps\": {len(todas_palavras_irrelevantes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardando as palavras irrelevantes como um pd.Series\n",
    "serie_irrelevante = pd.Series(todas_palavras_irrelevantes)\n",
    "\n",
    "# Frequencia absoluta de palavras relevantes\n",
    "tabela_irrelevante = serie_irrelevante.value_counts()\n",
    "#tabela_irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todas as palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4758"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total de palavras com repeti√ß√£o.\n",
    "total_de_palavras = todas_palavras_relevantes + todas_palavras_irrelevantes\n",
    "len(total_de_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = pd.concat([serie_relevante, serie_irrelevante])\n",
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_p_sem_r = x.value_counts().shape[0]\n",
    "#total_p_sem_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transformando em pd.Series.\n",
    "# serie_total_P= pd.Series(total_de_palavras)\n",
    "# # Verificando o total de palavras n√£o repetidas\n",
    "# total_P =serie_total_P.value_counts()\n",
    "# total_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Frequencia Relativa tbota\n",
    "\n",
    "# total_de_palavras = serie_total.value_counts()\n",
    "# total_de_palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teorema de Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35540142917192097\n",
      "0.35540142917192097\n",
      "4758\n"
     ]
    }
   ],
   "source": [
    "# Calculando as probabilidades \n",
    "\n",
    "Probabilidade_de_ser_relevante = len(todas_palavras_relevantes)/len(total_de_palavras)\n",
    "Probabilidade_de_ser_irrelevante = len(todas_palavras_irrelevantes)/len(total_de_palavras)\n",
    "print(Probabilidade_de_ser_relevante)\n",
    "print(Probabilidade_de_ser_relevante)\n",
    "print(len(total_de_palavras))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.59\n",
       "1    0.41\n",
       "Name: Irrelevante 0 / Relevante 1, dtype: float64"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planilha_teste = pd.read_excel('puma.xlsx', sheet_name = 'Teste')\n",
    "planilha_teste['Irrelevante 0 / Relevante 1'].value_counts(True)\n",
    "#planilha_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando apenas a planilha de Testes.\n",
    "t_teste = planilha_teste.loc[:, 'Teste']\n",
    "#t_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando os tweets de teste usando a fun√ß√£o que definimos como cleanup.\n",
    "lista2_limpa = []\n",
    "for index, argumento in enumerate (t_teste):\n",
    "    #print(f'posi√ß√£o {index} tweeter: {argumento}')\n",
    "    limpa = cleanup(argumento.lower())\n",
    "    lista2_limpa.append(limpa)\n",
    "    \n",
    "#print(lista2_limpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1¬∞ for: Separar os tweets relevantes em palavras relevantes dando um split\n",
    "lista_geral_teste= [] \n",
    "for c,conteudo in enumerate (lista2_limpa):\n",
    "    lista_geral_teste.append(conteudo.split())\n",
    "    \n",
    "#print(lista_geral_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo classifica√ß√£o dos tweets da planilha teste\n",
    "\n",
    "lista_classificador = []\n",
    "\n",
    "laplace_relevante = Probabilidade_de_ser_relevante\n",
    "laplace_irrelevante = Probabilidade_de_ser_irrelevante\n",
    "\n",
    "\n",
    "for tweet in lista_geral_teste:\n",
    "    \n",
    "    for palavra in tweet:\n",
    "    \n",
    "        if palavra not in tabela_relevante and palavra not in tabela_irrelevante:\n",
    "            laplace_relevante *= (0 + 1) / (len(todas_palavras_relevantes) + total_p_sem_r)\n",
    "            laplace_irrelevante *= (0 + 1) / (len(todas_palavras_irrelevantes) + total_p_sem_r)\n",
    "\n",
    "\n",
    "        elif palavra not in tabela_irrelevante and palavra in tabela_relevante:\n",
    "            laplace_irrelevante *= (0 + 1) / (len(todas_palavras_irrelevantes) + total_p_sem_r)\n",
    "            laplace_relevante *= (tabela_relevante[palavra] + 1) / (len(todas_palavras_relevantes) + total_p_sem_r)\n",
    "\n",
    "        elif palavra not in tabela_relevante and palavra in tabela_irrelevante:\n",
    "            laplace_relevante *= (0 + 1) / (len(todas_palavras_relevantes) + total_p_sem_r)\n",
    "            laplace_irrelevante *= (tabela_irrelevante[palavra] + 1) / (len(todas_palavras_irrelevantes) + total_p_sem_r)\n",
    "\n",
    "\n",
    "\n",
    "        elif palavra in tabela_relevante and palavra in tabela_irrelevante:\n",
    "            laplace_relevante *= (tabela_relevante[palavra] + 1) / (len(todas_palavras_relevantes) + total_p_sem_r)\n",
    "            laplace_irrelevante *= (tabela_irrelevante[palavra] + 1) / (len(todas_palavras_irrelevantes) + total_p_sem_r)\n",
    "\n",
    "\n",
    "\n",
    "    if laplace_relevante > laplace_irrelevante:\n",
    "        lista_classificador.append(1)\n",
    "    else:\n",
    "        lista_classificador.append(0)\n",
    "    \n",
    "    laplace_relevante = Probabilidade_de_ser_relevante\n",
    "    laplace_irrelevante = Probabilidade_de_ser_irrelevante\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Irrelevante 0 / Relevante 1</th>\n",
       "      <th>Algoritimo Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@0chavex0 @ornate_puma vdd to resfriado</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üìΩ neymar e puma üëÄ‚ù§!!\\ntemos novidades vindo a√≠...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@brgmsch mas a puma nem patrocina a aston</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üìΩ puma neymar jr creativity  a inovadora chute...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a puma t√° a evoluir muito, quem me dera que o ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>@mascaradinhoo esse √© bem pequeno, s√£o paulo c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>250,00 um puma √© pra fuder, que dor no peito</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>@puma_parda gente como a gente</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>@lewishamiltonbr @puma eu vendo a foto: https:...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>@neymarjr @pumafootball s√≥ queria um casaco de...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Teste  \\\n",
       "0             @0chavex0 @ornate_puma vdd to resfriado   \n",
       "1   üìΩ neymar e puma üëÄ‚ù§!!\\ntemos novidades vindo a√≠...   \n",
       "2           @brgmsch mas a puma nem patrocina a aston   \n",
       "3   üìΩ puma neymar jr creativity  a inovadora chute...   \n",
       "4   a puma t√° a evoluir muito, quem me dera que o ...   \n",
       "..                                                ...   \n",
       "25  @mascaradinhoo esse √© bem pequeno, s√£o paulo c...   \n",
       "26       250,00 um puma √© pra fuder, que dor no peito   \n",
       "27                     @puma_parda gente como a gente   \n",
       "28  @lewishamiltonbr @puma eu vendo a foto: https:...   \n",
       "29  @neymarjr @pumafootball s√≥ queria um casaco de...   \n",
       "\n",
       "    Irrelevante 0 / Relevante 1  Algoritimo Classificador  \n",
       "0                             0                         0  \n",
       "1                             1                         1  \n",
       "2                             0                         0  \n",
       "3                             1                         1  \n",
       "4                             1                         0  \n",
       "..                          ...                       ...  \n",
       "25                            0                         0  \n",
       "26                            0                         0  \n",
       "27                            0                         0  \n",
       "28                            0                         1  \n",
       "29                            1                         1  \n",
       "\n",
       "[30 rows x 3 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planilha_teste[\"Algoritimo Classificador\"] = lista_classificador\n",
    "planilha_teste.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Algoritimo Classificador</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irrelevante 0 / Relevante 1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.085</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algoritimo Classificador         0      1\n",
       "Irrelevante 0 / Relevante 1              \n",
       "0                            0.330  0.260\n",
       "1                            0.085  0.325"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(planilha_teste['Irrelevante 0 / Relevante 1'], planilha_teste['Algoritimo Classificador'], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
