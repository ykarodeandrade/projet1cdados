{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Rodrigo de Lima Azeredo\n",
    "\n",
    "Nome: Ykaro de Sousa Andrade"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando bibliotecas\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display\n",
    "pd.options.display.max_rows = 13\n",
    "import emoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\Rodrigo Lima\\Documents\\Cdados\\Projeto\\projet1cdados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo função de limpeza dos caracteres dos tweets e espaçando os emajis e palavras corretamente.\n",
    "\n",
    "def cleanup(text):\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;\\n)(*$#@''\"\"]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    text_subbed = emoji.get_emoji_regexp().split(text_subbed) #emoji\n",
    "    return ' '.join(text_subbed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'puma.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Irrelevante 0 / Relevante 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o neymar inovou a puma https://t.co/qtcuvd1svj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a @puma tá deitando nas chuteiras do neymar, m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fico assim no da puma affss https://t.co/1ygyh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@g_estrella__ puma tá aí , mas três listra tá ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@0ketlyn_s eu acho que um puma ^^</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  \\\n",
       "0     o neymar inovou a puma https://t.co/qtcuvd1svj   \n",
       "1  a @puma tá deitando nas chuteiras do neymar, m...   \n",
       "2  fico assim no da puma affss https://t.co/1ygyh...   \n",
       "3  @g_estrella__ puma tá aí , mas três listra tá ...   \n",
       "4                  @0ketlyn_s eu acho que um puma ^^   \n",
       "\n",
       "   Irrelevante 0 / Relevante 1  \n",
       "0                            1  \n",
       "1                            1  \n",
       "2                            0  \n",
       "3                            1  \n",
       "4                            0  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Irrelevante 0 / Relevante 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@0chavex0 @ornate_puma vdd to resfriado</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>📽 neymar e puma 👀❤!!\\ntemos novidades vindo aí...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@brgmsch mas a puma nem patrocina a aston</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>📽 puma neymar jr creativity  a inovadora chute...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a puma tá a evoluir muito, quem me dera que o ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  \\\n",
       "0            @0chavex0 @ornate_puma vdd to resfriado   \n",
       "1  📽 neymar e puma 👀❤!!\\ntemos novidades vindo aí...   \n",
       "2          @brgmsch mas a puma nem patrocina a aston   \n",
       "3  📽 puma neymar jr creativity  a inovadora chute...   \n",
       "4  a puma tá a evoluir muito, quem me dera que o ...   \n",
       "\n",
       "   Irrelevante 0 / Relevante 1  \n",
       "0                            0  \n",
       "1                            1  \n",
       "2                            0  \n",
       "3                            1  \n",
       "4                            1  "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "Para nosso projeto escolhemos a marca de roupas Puma. A partir disso definimos como premissa que os tweets relevantes seriam aqueles que exaltavam a marca em seus comentários, em contra partida os tweets irrelevantes seriam todos os outros, ou seja os que não tinham relação direta com a marca e/ou falavam mal da Puma.\n",
    "\n",
    "###\n",
    "Para nossa análise, escolhemos a marca Puma, onde nessa análise foi pego como tweets relevantes, todos aqueles que enaltecia a marca, tais twitts como: Falando o quanto a marca é boa e o quanto a mesma está crescendo no mercado.\n",
    "E qualificou-se como irrelevante os  tweets que rebaixava a marca ou os que realmente não tinha haver com a marca.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todos os tweets: Treinamentos\n",
    "dados = pd.read_excel('puma.xlsx')\n",
    "#dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando apenas a planilha de Treinamentos.\n",
    "t_treinamento = dados.loc[:, 'Treinamento']\n",
    "#t_treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando os tweets de treinamento usando a função que definimos como cleanup.\n",
    "lista_limpa = []\n",
    "for index, argumento in enumerate (t_treinamento):\n",
    "    #print(f'posição {index} tweeter: {argumento}')\n",
    "    limpa = cleanup(argumento.lower())\n",
    "    lista_limpa.append(limpa)\n",
    "    \n",
    "#print(lista_limpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Criando um novo data frame com os tweets de treinamentos limpos\n",
    "dados['Limpo'] = lista_limpa\n",
    "#dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando apenas os tweets relevantes e os adicionando em uma nova variável\n",
    "relevante = dados.loc[dados['Irrelevante 0 / Relevante 1'] == 1, 'Limpo']\n",
    "#relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1° for: Separar os tweets relevantes em palavras relevantes dando um split em cada tweet.\n",
    "p_relevantes = [] \n",
    "for c,conteudo in enumerate (relevante):\n",
    "    p_relevantes.append(conteudo.split())\n",
    "    \n",
    "#print(p_relevantes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Definindo todas as palvras revelantes em um conjunto\n",
    "todas_palavras_relevantes=[]\n",
    "for index, conteudo in enumerate(p_relevantes):\n",
    "    cont=0\n",
    "    while cont < len(p_relevantes[index]):\n",
    "        novo= conteudo[cont]\n",
    "        todas_palavras_relevantes.append(novo)\n",
    "        cont+=1\n",
    "#print(todas_palavras_relevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O total de Palavras relevantes é 1730\n"
     ]
    }
   ],
   "source": [
    "# Informando o total de palavras dos tweets relevantes\n",
    "print(f' O total de Palavras relevantes é {len(todas_palavras_relevantes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo uma nova limpeza, retirando todos os https.\n",
    "for index, conteudo in enumerate(todas_palavras_relevantes):\n",
    "    #print(f'{index}: {conteudo}')\n",
    "    cont = 0\n",
    "    while cont < len(todas_palavras_relevantes[index]):\n",
    "        #print(conteudo[cont])\n",
    "        if conteudo[cont:5] == 'https':\n",
    "            #print(f' palvra: {lista[index]} na posição {index}')\n",
    "            lista_de_links.append(todas_palavras_relevantes[index])\n",
    "        cont+=1\n",
    "\n",
    "lista_nova_r = []\n",
    "cont2 = 0\n",
    "while cont2 < len(todas_palavras_relevantes):\n",
    "    if todas_palavras_relevantes[cont2] not in lista_de_links:\n",
    "        lista_nova_r.append(todas_palavras_relevantes[cont2])\n",
    "    cont2+=1\n",
    "\n",
    "# Atualização da variável todas_palavras_relevantes sem os https:\n",
    "\n",
    "todas_palavras_relevantes= lista_nova_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O total de Palavras relevantes sem os \"htpps\" é 1691\n"
     ]
    }
   ],
   "source": [
    "print(f' O total de Palavras relevantes sem os \"htpps\" é {len(todas_palavras_relevantes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Guardando as palavras como um pd.Series\n",
    "serie_relevante = pd.Series(todas_palavras_relevantes)\n",
    "\n",
    "# Frequencia absoluta de palavras relevantes\n",
    "tabela_relevante = serie_relevante.value_counts()\n",
    "#tabela_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Fazendo o mesmo para as palavras irrelevantes\"></div>\n",
    "\n",
    "### Fazendo o mesmo para as palavras irrelevantes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando apenas os tweets irrelevantes e os adicionando em uma nova variável\n",
    "irrelevante = dados.loc[dados['Irrelevante 0 / Relevante 1'] == 0, 'Limpo']\n",
    "#irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1° for: Separar os tweets relevantes em palavras irrelevantes dando um split em cada tweet.\n",
    "p_irrelevantes = []\n",
    "for index, conteudo in enumerate (irrelevante):\n",
    "    p_irrelevantes.append(conteudo.split())\n",
    "    \n",
    "# print(p_irrelevantes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Definindo todas as palvras irrevelantes em um conjunto\n",
    "todas_palavras_irrelevantes=[]\n",
    "for index, conteudo in enumerate(p_irrelevantes):\n",
    "    cont=0\n",
    "    while cont < len(p_irrelevantes[index]):\n",
    "        novo= conteudo[cont]\n",
    "        todas_palavras_irrelevantes.append(novo)\n",
    "        cont+=1\n",
    "#print(todas_palavras_irrelevantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O total de Palavras irrelevantes é 3115\n"
     ]
    }
   ],
   "source": [
    "# Informando o total de palavras dos tweets relevantes\n",
    "print(f' O total de Palavras irrelevantes é {len(todas_palavras_irrelevantes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lista_de_links= []\n",
    "for index, conteudo in enumerate(todas_palavras_irrelevantes):\n",
    "    #print(f'{index}: {conteudo}')\n",
    "    cont = 0\n",
    "    while cont < len(todas_palavras_irrelevantes[index]):\n",
    "        #print(conteudo[cont])\n",
    "        if conteudo[cont:5] == 'https':\n",
    "            #print(f' palvra: {lista[index]} na posição {index}')\n",
    "            lista_de_links.append(todas_palavras_irrelevantes[index])\n",
    "        cont+=1\n",
    "\n",
    "lista_nova_irr = []\n",
    "cont2 = 0\n",
    "while cont2 < len(todas_palavras_irrelevantes):\n",
    "    if todas_palavras_irrelevantes[cont2] not in lista_de_links:\n",
    "        lista_nova_irr.append(todas_palavras_irrelevantes[cont2])\n",
    "    cont2+=1\n",
    "\n",
    "# Atualização da variável todas_palavras_relevantes sem os https:\n",
    "\n",
    "todas_palavras_irrelevantes= lista_nova_irr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O total de Palavras irrelevantes sem os \"htpps\": 3067\n"
     ]
    }
   ],
   "source": [
    "print(f' O total de Palavras irrelevantes sem os \"htpps\": {len(todas_palavras_irrelevantes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardando as palavras irrelevantes como um pd.Series\n",
    "serie_irrelevante = pd.Series(todas_palavras_irrelevantes)\n",
    "\n",
    "# Frequencia absoluta de palavras relevantes\n",
    "tabela_irrelevante = serie_irrelevante.value_counts()\n",
    "#tabela_irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todas as palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O total de palavras com repetição é 4758\n"
     ]
    }
   ],
   "source": [
    "# Total de palavras com repetição.\n",
    "total_de_palavras = todas_palavras_relevantes + todas_palavras_irrelevantes\n",
    "print(f'O total de palavras com repetição é {len(total_de_palavras)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = pd.concat([serie_relevante, serie_irrelevante])\n",
    "#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_p_sem_r = x.value_counts().shape[0]\n",
    "#total_p_sem_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teorema de Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35540142917192097\n",
      "0.35540142917192097\n",
      "4758\n"
     ]
    }
   ],
   "source": [
    "# Calculando as probabilidades \n",
    "\n",
    "Probabilidade_de_ser_relevante = len(todas_palavras_relevantes)/len(total_de_palavras)\n",
    "Probabilidade_de_ser_irrelevante = len(todas_palavras_irrelevantes)/len(total_de_palavras)\n",
    "print(Probabilidade_de_ser_relevante)\n",
    "print(Probabilidade_de_ser_relevante)\n",
    "print(len(total_de_palavras))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.59\n",
       "1    0.41\n",
       "Name: Irrelevante 0 / Relevante 1, dtype: float64"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planilha_teste = pd.read_excel('puma.xlsx', sheet_name = 'Teste')\n",
    "planilha_teste['Irrelevante 0 / Relevante 1'].value_counts(True)\n",
    "#planilha_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando apenas a planilha de Testes.\n",
    "t_teste = planilha_teste.loc[:, 'Teste']\n",
    "#t_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando os tweets de teste usando a função que definimos como cleanup.\n",
    "lista2_limpa = []\n",
    "for index, argumento in enumerate (t_teste):\n",
    "    #print(f'posição {index} tweeter: {argumento}')\n",
    "    limpa = cleanup(argumento.lower())\n",
    "    lista2_limpa.append(limpa)\n",
    "    \n",
    "#print(lista2_limpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1° for: Separar os tweets relevantes em palavras relevantes dando um split\n",
    "lista_geral_teste= [] \n",
    "for c,conteudo in enumerate (lista2_limpa):\n",
    "    lista_geral_teste.append(conteudo.split())\n",
    "    \n",
    "#print(lista_geral_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teorema de Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo classificação dos tweets da planilha teste\n",
    "\n",
    "lista_classificador = []\n",
    "\n",
    "laplace_relevante = Probabilidade_de_ser_relevante\n",
    "laplace_irrelevante = Probabilidade_de_ser_irrelevante\n",
    "\n",
    "\n",
    "for tweet in lista_geral_teste:\n",
    "    \n",
    "    for palavra in tweet:\n",
    "    \n",
    "        if palavra not in tabela_relevante and palavra not in tabela_irrelevante:\n",
    "            laplace_relevante *= (0 + 1) / (len(todas_palavras_relevantes) + total_p_sem_r)\n",
    "            laplace_irrelevante *= (0 + 1) / (len(todas_palavras_irrelevantes) + total_p_sem_r)\n",
    "\n",
    "\n",
    "        elif palavra not in tabela_irrelevante and palavra in tabela_relevante:\n",
    "            laplace_irrelevante *= (0 + 1) / (len(todas_palavras_irrelevantes) + total_p_sem_r)\n",
    "            laplace_relevante *= (tabela_relevante[palavra] + 1) / (len(todas_palavras_relevantes) + total_p_sem_r)\n",
    "\n",
    "        elif palavra not in tabela_relevante and palavra in tabela_irrelevante:\n",
    "            laplace_relevante *= (0 + 1) / (len(todas_palavras_relevantes) + total_p_sem_r)\n",
    "            laplace_irrelevante *= (tabela_irrelevante[palavra] + 1) / (len(todas_palavras_irrelevantes) + total_p_sem_r)\n",
    "\n",
    "\n",
    "\n",
    "        elif palavra in tabela_relevante and palavra in tabela_irrelevante:\n",
    "            laplace_relevante *= (tabela_relevante[palavra] + 1) / (len(todas_palavras_relevantes) + total_p_sem_r)\n",
    "            laplace_irrelevante *= (tabela_irrelevante[palavra] + 1) / (len(todas_palavras_irrelevantes) + total_p_sem_r)\n",
    "\n",
    "\n",
    "\n",
    "    if laplace_relevante > laplace_irrelevante:\n",
    "        lista_classificador.append(1)\n",
    "    else:\n",
    "        lista_classificador.append(0)\n",
    "    \n",
    "    laplace_relevante = Probabilidade_de_ser_relevante\n",
    "    laplace_irrelevante = Probabilidade_de_ser_irrelevante\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Irrelevante 0 / Relevante 1</th>\n",
       "      <th>Algoritimo Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@0chavex0 @ornate_puma vdd to resfriado</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>📽 neymar e puma 👀❤!!\\ntemos novidades vindo aí...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@brgmsch mas a puma nem patrocina a aston</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>📽 puma neymar jr creativity  a inovadora chute...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a puma tá a evoluir muito, quem me dera que o ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>@mascaradinhoo esse é bem pequeno, são paulo c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>250,00 um puma é pra fuder, que dor no peito</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>@puma_parda gente como a gente</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>@lewishamiltonbr @puma eu vendo a foto: https:...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>@neymarjr @pumafootball só queria um casaco de...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Teste  \\\n",
       "0             @0chavex0 @ornate_puma vdd to resfriado   \n",
       "1   📽 neymar e puma 👀❤!!\\ntemos novidades vindo aí...   \n",
       "2           @brgmsch mas a puma nem patrocina a aston   \n",
       "3   📽 puma neymar jr creativity  a inovadora chute...   \n",
       "4   a puma tá a evoluir muito, quem me dera que o ...   \n",
       "..                                                ...   \n",
       "25  @mascaradinhoo esse é bem pequeno, são paulo c...   \n",
       "26       250,00 um puma é pra fuder, que dor no peito   \n",
       "27                     @puma_parda gente como a gente   \n",
       "28  @lewishamiltonbr @puma eu vendo a foto: https:...   \n",
       "29  @neymarjr @pumafootball só queria um casaco de...   \n",
       "\n",
       "    Irrelevante 0 / Relevante 1  Algoritimo Classificador  \n",
       "0                             0                         0  \n",
       "1                             1                         1  \n",
       "2                             0                         0  \n",
       "3                             1                         1  \n",
       "4                             1                         0  \n",
       "..                          ...                       ...  \n",
       "25                            0                         0  \n",
       "26                            0                         0  \n",
       "27                            0                         0  \n",
       "28                            0                         1  \n",
       "29                            1                         1  \n",
       "\n",
       "[30 rows x 3 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planilha_teste[\"Algoritimo Classificador\"] = lista_classificador\n",
    "planilha_teste.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Algoritimo Classificador</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irrelevante 0 / Relevante 1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.085</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Algoritimo Classificador         0      1\n",
       "Irrelevante 0 / Relevante 1              \n",
       "0                            0.330  0.260\n",
       "1                            0.085  0.325"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(planilha_teste['Irrelevante 0 / Relevante 1'], planilha_teste['Algoritimo Classificador'], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
